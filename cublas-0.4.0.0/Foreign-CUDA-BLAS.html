<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Foreign.CUDA.BLAS</title><link href="ocean.css" rel="stylesheet" type="text/css" title="Ocean" /><script src="haddock-util.js" type="text/javascript"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script><script type="text/javascript">//<![CDATA[
window.onload = function () {pageLoad();};
//]]>
</script></head><body><div id="package-header"><ul class="links" id="page-menu"><li><a href="src/Foreign.CUDA.BLAS.html">Source</a></li><li><a href="index.html">Contents</a></li><li><a href="doc-index.html">Index</a></li></ul><p class="caption">cublas-0.4.0.0: FFI bindings to the CUDA BLAS library</p></div><div id="content"><div id="module-header"><table class="info"><tr><th valign="top">Copyright</th><td>[2014..2017] Trevor L. McDonell</td></tr><tr><th>License</th><td>BSD3</td></tr><tr><th>Maintainer</th><td>Trevor L. McDonell &lt;tmcdonell@cse.unsw.edu.au&gt;</td></tr><tr><th>Stability</th><td>experimental</td></tr><tr><th>Portability</th><td>non-portable (GHC extensions)</td></tr><tr><th>Safe Haskell</th><td>None</td></tr><tr><th>Language</th><td>Haskell98</td></tr></table><p class="caption">Foreign.CUDA.BLAS</p></div><div id="table-of-contents"><p class="caption">Contents</p><ul><li><a href="#g:1">Control</a></li><li><a href="#g:2">Operations</a></li></ul></div><div id="description"><p class="caption">Description</p><div class="doc"><p>The cuBLAS library is an implementation of BLAS (Basic Linear Algebra
 Subprograms) for NVIDIA GPUs.</p><p>To use operations from the cuBLAS library, the user must allocate the
 required matrices and vectors in the GPU memory space, fill them with data,
 call the desired sequence of cuBLAS functions, then copy the results from the
 GPU memory space back to the host.</p><p>The <a href="http://hackage.haskell.org/package/cuda">cuda</a> package can be used for
 writing to and retrieving data from the GPU.</p><dl><dt><em>Data layout</em></dt><dd></dd></dl><p>Unlike modern BLAS libraries, cuBLAS <em>only</em> provides Fortran-style
 implementations of the subprograms, using column-major storage and 1-based
 indexing.</p><p>The <code><a href="http://docs.nvidia.com/cuda/cublas/index.html#cublas-lt-t-gt-geam">?geam</a></code>
 operation can be used to perform matrix transposition.</p><dl><dt><em>Example</em></dt><dd></dd></dl><p>At a short example, we show how to compute the following matrix-matrix
 product with <code><a href="Foreign-CUDA-BLAS-Level3.html#v:dgemm">dgemm</a></code>:</p><p>\[
 \left(\begin{matrix} 1 &amp; 2 \\ 3 &amp; 4 \\ 5 &amp; 6 \\ \end{matrix}\right) \cdot
 \left(\begin{matrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ \end{matrix}\right)  =
 \left(\begin{matrix} 9 &amp; 12 &amp; 15 \\ 19 &amp; 26 &amp; 33 \\ 29 &amp; 40 &amp; 51 \\ \end{matrix}\right)
 \]</p><p>I assume you know how to initialise the CUDA
 environment, as described in the <a href="../cuda-0.9.0.0/Foreign-CUDA-Driver.html">Foreign.CUDA.Driver</a> module:</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>import Foreign.CUDA.Driver as CUDA
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>import Foreign.CUDA.BLAS as BLAS
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>CUDA.initialise []
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>dev &lt;- CUDA.device 0
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>ctx &lt;- CUDA.create dev []
</code></strong></pre><p>Just as we must create a CUDA execution context with
 <code><a href="../cuda-0.9.0.0/Foreign-CUDA-Driver.html#v:create">create</a></code> before interacting with the GPU, we must create
 a BLAS context handle before executing any cuBLAS library operations, which
 will be associated with the current device context:</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>hdl &lt;- BLAS.create
</code></strong></pre><p>Now, let us generate the matrix data on the GPU. (For simplicity in this
 example we will just marshal the data via lists, but in a real application
 with a large amount of data we should of course use some kind of unboxed
 array):</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>let rowsA = 3; colsA = 2; sizeA = rowsA * colsA
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>let rowsB = 2; colsB = 3; sizeB = rowsB * colsB
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>let sizeC = rowsA * colsB
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>matA &lt;- CUDA.newListArray (take sizeA [1..])
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>matB &lt;- CUDA.newListArray (take sizeB [1..])
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>matC &lt;- CUDA.mallocArray sizeC
</code></strong></pre><p>Note in the above that we store data in row-major order, as is the convention
 in C. However, the cuBLAS library assumes a column-major representation, as
 is the style of Fortran. However, we can make use of the following
 equivalency:</p><p>\[
 B^T \cdot A^T = (A \cdot B)^T
 \]</p><p>and, since the transposed matrix in column-major representation is equivalent
 to our matrix in row-major representation, we can avoid any actual data
 manipulation to get things into a form suitable for cuBLAS (phew!).</p><p>The final thing to take care of are the scaling parameters to the <code><a href="Foreign-CUDA-BLAS-Level3.html#v:dgemm">dgemm</a></code>
 operation, \(\alpha\) and \(\beta\). By default, it is assumed that these
 values reside in host memory, but this setting can be changed with
 <code><a href="Foreign-CUDA-BLAS-Context.html#v:setPointerMode">setPointerMode</a></code>; When set to <code><a href="Foreign-CUDA-BLAS-Context.html#v:Device">Device</a></code> mode, the function
 <code><a href="../cuda-0.9.0.0/Foreign-CUDA-Ptr.html#v:withDevicePtr">withDevicePtr</a></code> can be used to treat the device memory
 pointer as a plain pointer to pass to the function.</p><p>Now, we are ready to piece it all together:</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>import Foreign.Marshal
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>with 1.0 $ \alpha -&gt;
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>with 0.0 $ \beta -&gt;
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>dgemm hdl N N colsB rowsA colsA alpha matB colsB matA colsA beta matC colsB
</code></strong></pre><p>And retrieve the result:</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>print =&lt;&lt; CUDA.peekListArray sizeC matC
</code></strong>[9.0,12.0,15.0,19.0,26.0,33.0,29.0,40.0,51.0]
</pre><p>Finally, we should <code><a href="../cuda-0.9.0.0/Foreign-CUDA-Driver.html#v:free">free</a></code> the device memory we allocated,
 and release the BLAS context handle:</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>BLAS.destroy hdl
</code></strong></pre><dl><dt><em>Additional information</em></dt><dd></dd></dl><p>For more information, see the NVIDIA cuBLAS documentation:</p><p><a href="http://docs.nvidia.com/cuda/cublas/index.html">http://docs.nvidia.com/cuda/cublas/index.html</a></p></div></div><div id="synopsis"><p id="control.syn" class="caption expander" onclick="toggleSection('syn')">Synopsis</p><ul id="section.syn" class="hide" onclick="toggleSection('syn')"><li class="src short">module <a href="Foreign-CUDA-BLAS-Context.html">Foreign.CUDA.BLAS.Context</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Stream.html">Foreign.CUDA.BLAS.Stream</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Error.html">Foreign.CUDA.BLAS.Error</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Level1.html">Foreign.CUDA.BLAS.Level1</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Level2.html">Foreign.CUDA.BLAS.Level2</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Level3.html">Foreign.CUDA.BLAS.Level3</a></li></ul></div><div id="interface"><h1 id="g:1">Control</h1><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Context.html">Foreign.CUDA.BLAS.Context</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Stream.html">Foreign.CUDA.BLAS.Stream</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Error.html">Foreign.CUDA.BLAS.Error</a></p></div><h1 id="g:2">Operations</h1><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Level1.html">Foreign.CUDA.BLAS.Level1</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Level2.html">Foreign.CUDA.BLAS.Level2</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Level3.html">Foreign.CUDA.BLAS.Level3</a></p></div></div></div><div id="footer"><p>Produced by <a href="http://www.haskell.org/haddock/">Haddock</a> version 2.18.1</p></div></body></html>