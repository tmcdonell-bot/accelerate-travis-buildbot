-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Accelerate backend generating LLVM
--   
--   This library implements direct LLVM IR generation for the
--   <i>Accelerate</i> language. For further information, refer to the main
--   <i>Accelerate</i> package:
--   <a>http://hackage.haskell.org/package/accelerate</a>
@package accelerate-llvm
@version 2.0.0.0


module Data.Range.Range

-- | A simple range data type
data Range

-- | The empty range
Empty :: Range

-- | A range span with inclusive left, exclusive right
IE :: !Int -> !Int -> Range

-- | An empty interval
empty :: Range

-- | Check if an interval is empty
null :: Range -> Bool

-- | A singleton point
singleton :: Int -> Range

-- | A range span with exclusive endpoint [u,v).
(...) :: Int -> Int -> Range

-- | <i>O(1)</i>. The number of elements defined by the range interval
size :: Range -> Int

-- | <i>O(1)</i>. Split an interval into two roughly equally sized ranges.
--   If the interval is odd then the first interval gets the extra element.
bisect :: Range -> (Range, Range)

-- | <i>O(1)</i>. Return the first <tt>n</tt> elements of the range, or the
--   range itself if <tt>n &gt; size</tt>.
take :: Int -> Range -> Range

-- | <i>O(1)</i>. A tuple where the first element is the first <tt>n</tt>
--   elements of the range, and the second is the remainder of the list (if
--   any).
splitAt :: Int -> Range -> (Range, Range)

-- | If the two ranges are adjacent, return one combined range. The ranges
--   must not be empty.
merge :: Range -> Range -> Maybe Range

-- | <i>O(1)</i>. Add a new range to the end of the given sequence. We
--   assume that ranges are non-overlapping and non-empty. If the new range
--   is adjacent to the last range on the sequence, the ranges are
--   appended.
append :: Seq Range -> Range -> Seq Range

-- | <i>O(n log n)</i>. Compress the given ranges into the fewest number of
--   sections as possible. The ranges must not be empty.
compress :: Seq Range -> Seq Range
instance GHC.Classes.Eq Data.Range.Range.Range
instance GHC.Show.Show Data.Range.Range.Range


module Control.Parallel.Meta.Worker

-- | The <a>Gang</a> structure tracks the state of all workers in the
--   program. It starts empty, and workers append to it as they are brought
--   online. Although the vector append operation is expensive, it is
--   expected it is only called occasionally; e.g. at program
--   initialisation. So, we prioritise for constant lookup of the worker
--   structure, which will be done frequently during the work search.
type Gang = Vector Worker

-- | The <a>Worker</a> is the per-worker-thread state.
--   
--   If the worker has work that can be stolen by other processors, it is
--   stored in the <a>workpool</a>. Thieves treat the workpool as a stack
--   which can be popped on the right, where as the owner can both push and
--   pop on the left.
--   
--   In the lazy binary splitting work stealing setup, a worker processes
--   its range in chunks, checking the state of its workpool periodically.
--   Whenever the queue is empty, it splits it's current workload in two so
--   that the second half can be stolen by another processor.
data Worker
Worker :: {-# UNPACK #-} !Int -> {-# UNPACK #-} !(MVar Req) -> {-# UNPACK #-} !(MVar ()) -> {-# UNPACK #-} !(WSDeque Range) -> {-# UNPACK #-} !(IORef Int) -> {-# UNPACK #-} !GenIO -> Worker
[workerId] :: Worker -> {-# UNPACK #-} !Int
[requestVar] :: Worker -> {-# UNPACK #-} !(MVar Req)
[resultVar] :: Worker -> {-# UNPACK #-} !(MVar ())
[workpool] :: Worker -> {-# UNPACK #-} !(WSDeque Range)
[consecutiveFailures] :: Worker -> {-# UNPACK #-} !(IORef Int)
[rngState] :: Worker -> {-# UNPACK #-} !GenIO

-- | The <a>Req</a> type encapsulates work requests for individual workers
data Req

-- | Instruct the worker to run the given action
ReqDo :: (Int -> IO ()) -> Req

-- | Tell the worker to exit. The worker should signal that it received the
--   request by writing its result var before exiting.
ReqShutdown :: Req

-- | O(1). Yield the number of threads in the <a>Gang</a>.
gangSize :: Gang -> Int

-- | Create a set of workers. This is a somewhat expensive function, so it
--   is expected that it is called only occasionally (e.g. once per program
--   execution).
forkGang :: Int -> IO Gang

-- | Create a set of workers on specific capabilities. Note that the thread
--   ID passed to the <a>gangWorker</a> is the index of this worker in the
--   gang structure, not necessarily the capability is is spawned on.
forkGangOn :: [Int] -> IO Gang

-- | Issue work requests to the gang and wait until they complete
gangIO :: Gang -> (Int -> IO ()) -> IO ()

-- | Check whether the work queues of the gang are all empty
exhausted :: Gang -> IO Bool
instance GHC.Classes.Eq Control.Parallel.Meta.Worker.Worker


module Control.Parallel.Meta

-- | The <a>Startup</a> component of a <a>Resource</a> is a callback that
--   implements initialisation behaviour. For example, it might contact
--   remote hosts, spawn threads, or initialise hardware such as GPUs.
data Startup
Startup :: (Gang -> IO ()) -> Startup
[runStartup] :: Startup -> Gang -> IO ()

-- | The <a>WorkSearch</a> component of a <a>Resource</a> is a callback
--   that responds to requests for work from meta-workers. The arguments to
--   <a>WorkSearch</a> are the scheduler state for the current thread and a
--   reference to all workers in the program.
data WorkSearch
WorkSearch :: (Worker -> IO (Maybe Range)) -> WorkSearch
[runWorkSearch] :: WorkSearch -> Worker -> IO (Maybe Range)

-- | A <a>Resource</a> provides an abstraction of heterogeneous execution
--   resources that may be combined. Composition of resources is
--   left-biased. That is, if if <tt>resource1</tt> always returns work
--   from its <a>WorkSearch</a>, then the composed resource <tt>resource1
--   &lt;&gt; resource2</tt> will never request work from
--   <tt>resource2</tt>.
data Resource
Resource :: Startup -> WorkSearch -> Resource
[startup] :: Resource -> Startup
[workSearch] :: Resource -> WorkSearch

-- | An action to execute. The first parameters are the start and end
--   indices of the range this action should process, and the final is the
--   ID of the thread doing the work.
type Action = Int -> Int -> Int -> IO ()

-- | An <a>Executable</a> provides a callback that can be used to run a
--   provided function using an encapsulated work-stealing gang of threads.
data Executable
Executable :: (Int -> Range -> Finalise -> Maybe Action -> Action -> IO ()) -> Executable
[runExecutable] :: Executable -> Int -> Range -> Finalise -> Maybe Action -> Action -> IO ()

-- | The <a>Finalise</a> component of an executable is an action the thread
--   applies after processing the work function, given its thread id the
--   ranges that this thread actually handled.
data Finalise
Finalise :: (Int -> Seq Range -> IO ()) -> Finalise
[runFinalise] :: Finalise -> Int -> Seq Range -> IO ()

-- | Run a parallel work-stealing operation.
--   
--   Each thread initialises its work queue with an equally sized chunk of
--   the work. Threads keep working until their work search returns
--   Nothing, at which point the thread exits. In our LBS implementation, a
--   worker thread takes a small chunk of its work range to process, and
--   places the remainder back onto its deque. Thus the work queues are
--   only empty:
--   
--   (a) Briefly during the scheduling process; or
--   
--   (b) After the deque has been robbed. If the stolen chunk is large
--   enough, the stealee will split the remainder onto its deque to be
--   stolen; or
--   
--   (c) There is no more work.
--   
--   As long as the thread makes a small number of retries, this should
--   correctly balance the work without too much scheduler overhead.
--   
--   An alternative to every thread initialising with an even chunk size is
--   to put the entire range onto the first worker and then have the
--   scheduler handle the decomposition. However, since we are playing
--   fast-and-loose with the exit condition, this is a little racy.
--   
--   TLM NOTE:
--   
--   Should threads check whether the work queues of all threads are empty
--   before deciding to exit? If the PPT is too large then threads might
--   not react quickly enough to splitting once their deque is emptied.
--   Maybe the first thread to return Nothing can probe the queues to see
--   if they are all empty. If True, write into a shared MVar to signal to
--   the others that it is time to exit. But, that still assumes that the
--   PPT is not so large that the queues are always empty.
--   
--   TLM TODO:
--   
--   Splitting work should probably be biased to cache-size chunks, rather
--   than trying to split exactly evenly.
runParIO :: Resource -> Gang -> Range -> Maybe Action -> Action -> Finalise -> IO ()
seqIO :: Resource -> Gang -> Range -> Maybe Action -> Action -> Finalise -> IO ()
parIO :: Resource -> Gang -> Range -> Maybe Action -> Action -> Finalise -> IO ()
instance GHC.Base.Monoid Control.Parallel.Meta.Startup
instance GHC.Base.Monoid Control.Parallel.Meta.WorkSearch
instance GHC.Base.Monoid Control.Parallel.Meta.Resource
instance GHC.Base.Monoid Control.Parallel.Meta.Finalise


-- | This module implements exponential backoff so as to prevent spamming
--   of stealing actions. Most scheduler compositions should include this
--   at the bottom of the stack.
--   
--   Inspired by the meta-par package. This package has a BSD license.
--   <a>http://hackage.haskell.org/package/meta-par</a>
module Control.Parallel.Meta.Resource.Backoff
mkResource :: Resource
defaultWorkSearch :: WorkSearch

-- | To construct the work search, we need to know the minimum and maximum
--   amount of time, in nanoseconds, to sleep. The exponential backoff
--   policy is always the same: it starts at 1Âµs and doubles at every
--   failure.
--   
--   The thing that changes over time is whether sleeping actually occurs.
--   For example, the <a>defaultWorkSearch</a>:
--   
--   <pre>
--   mkWorkSearch 100 10000
--   </pre>
--   
--   will not sleep for the first 7 invocations (until 128), and then will
--   sleep an amount that doubles each time until it surpasses the maximum,
--   at which point it will always sleep for the maximum time (10ms)
mkWorkSearch :: Int -> Int -> WorkSearch


module Control.Parallel.Meta.Resource.Single

-- | Create a resource where each thread works in isolation. The resource
--   is not aware of any other sources of work (at this level) and only
--   ever tries to pop from its own local queue.
mkResource :: Resource


-- | This module implements a resource for SMP parallelism. It is suitable
--   as a base for combining a bunch of resources that can steal cheaply
--   from each other.
--   
--   Inspired by the meta-par package. This package has a BSD license.
--   <a>http://hackage.haskell.org/package/meta-par</a>
module Control.Parallel.Meta.Resource.SMP

-- | Create an SMP (symmetric multiprocessor) resource where all underlying
--   workers have uniform access to shared resources such as memory. Thus
--   workers at this level can steal cheaply from each other.
mkResource :: Int -> Gang -> Resource

-- | Given a set of workers and a number of steal attempts per worker,
--   return a work search function. Steals from workers in this gang are
--   considered cheap and uniform.
--   
--   Note: [Number of retries in SMP resource]
--   
--   A large number of retries in the work search will prevent the search
--   function from traversing the resource stack. This can result in
--   spamming of stealing actions. In particular, the exponential backoff
--   resource usually placed at the bottom of the stack may never be
--   reached. Thus a balance is required between number of times to
--   traverse each level and number of times to traverse the entire
--   resource stack.
mkWorkSearch :: Int -> Gang -> WorkSearch


-- | This module implements a lazy binary splitting resource transformer.
--   It is suitable to add an adaptive runtime work-stealing component to
--   resource.
module Control.Parallel.Meta.Trans.LBS

-- | Transform the <a>WorkSearch</a> function of the given <a>Resource</a>
--   to include a lazy binary splitting work stealing scheduler.
mkResource :: Int -> Resource -> Resource

-- | This transforms the <a>WorkSearch</a> function to add a lazy binary
--   splitting operation on top of an existing (work-stealing) scheduler.
--   On receiving a unit of work, the scheduler proceeds as follows:
--   
--   <ol>
--   <li>If the number of iterations is less than the profitable
--   parallelism threshold (ppt), execute the remaining iterations and
--   exit, else (2).</li>
--   <li>Check this worker's remaining work queue. If it is not empty, then
--   execute ppt iterations, then go to (1) with the remainder.</li>
--   <li>If the remaining work queue is empty, split this work chunk in
--   half. Place the second half onto the remaining work queue and go to
--   (1).</li>
--   </ol>
mkWorkSearch :: Int -> WorkSearch -> WorkSearch


-- | Generate types for the reified elements of an array computation
module Data.Array.Accelerate.LLVM.Util

-- | The number of bits in a type
bitSize :: Bits a => a -> Word32

-- | Convert a boolean value into an integral value, where False is zero
--   and True is one.
fromBool :: Integral i => Bool -> i

-- | Convert an integral value into a boolean. We follow the C convention,
--   where zero is False and all other values represent True.
toBool :: Integral i => i -> Bool


module LLVM.General.AST.Type.Flags
data NSW
NoSignedWrap :: NSW
SignedWrap :: NSW
data NUW
NoUnsignedWrap :: NUW
UnsignedWrap :: NUW
data FastMathFlags :: *
NoFastMathFlags :: FastMathFlags
UnsafeAlgebra :: FastMathFlags
FastMathFlags :: Bool -> Bool -> Bool -> Bool -> FastMathFlags
[noNaNs] :: FastMathFlags -> Bool
[noInfs] :: FastMathFlags -> Bool
[noSignedZeros] :: FastMathFlags -> Bool
[allowReciprocal] :: FastMathFlags -> Bool
instance Data.Default.Class.Default LLVM.General.AST.Type.Flags.NSW
instance Data.Default.Class.Default LLVM.General.AST.Type.Flags.NUW
instance Data.Default.Class.Default LLVM.General.AST.Instruction.FastMathFlags


module LLVM.General.AST.Type.Name

-- | Objects of various sorts in LLVM IR are identified by address in the
--   LLVM C++ API, and may be given a string name. When printed to (resp.
--   read from) human-readable LLVM assembly, objects without string names
--   are numbered sequentially (resp. must be numbered sequentially).
--   String names may be quoted, and are quoted when printed if they would
--   otherwise be misread - e.g. when containing special characters.
--   
--   <pre>
--   7
--   </pre>
--   
--   means the seventh unnamed object, while
--   
--   <pre>
--   "7"
--   </pre>
--   
--   means the object named with the string "7".
--   
--   This libraries handling of <a>UnName</a>s during translation of the
--   AST down into C++ IR is somewhat more forgiving than the LLVM assembly
--   parser: it does not require that unnamed values be numbered
--   sequentially; however, the numbers of <a>UnName</a>s passed into C++
--   cannot be preserved in the C++ objects. If the C++ IR is printed as
--   assembly or translated into a Haskell AST, unnamed nodes will be
--   renumbered sequentially. Thus unnamed node numbers should be thought
--   of as having any scope limited to the <a>Module</a> in which they are
--   used.
data Name a

-- | a string name
Name :: String -> Name a

-- | a number for a nameless thing
UnName :: Word -> Name a
data Label
Label :: String -> Label
instance Data.Data.Data LLVM.General.AST.Type.Name.Label
instance GHC.Show.Show LLVM.General.AST.Type.Name.Label
instance GHC.Read.Read LLVM.General.AST.Type.Name.Label
instance GHC.Classes.Ord LLVM.General.AST.Type.Name.Label
instance GHC.Classes.Eq LLVM.General.AST.Type.Name.Label
instance Data.Data.Data a => Data.Data.Data (LLVM.General.AST.Type.Name.Name a)
instance GHC.Show.Show (LLVM.General.AST.Type.Name.Name a)
instance GHC.Read.Read (LLVM.General.AST.Type.Name.Name a)
instance GHC.Classes.Ord (LLVM.General.AST.Type.Name.Name a)
instance GHC.Classes.Eq (LLVM.General.AST.Type.Name.Name a)
instance Data.String.IsString (LLVM.General.AST.Type.Name.Name a)
instance Data.String.IsString LLVM.General.AST.Type.Name.Label


module LLVM.General.AST.Type.Constant

-- | Although constant expressions and instructions have many similarities,
--   there are important differences - so they're represented using
--   different types in this AST. At the cost of making it harder to move
--   an code back and forth between being constant and not, this approach
--   embeds more of the rules of what IR is legal into the Haskell types.
--   
--   <a>http://llvm.org/docs/LangRef.html#constants</a>
--   
--   <a>http://llvm.org/docs/LangRef.html#constant-expressions</a>
data Constant a
ScalarConstant :: ScalarType a -> a -> Constant a
GlobalReference :: Maybe (ScalarType a) -> Name a -> Constant a


module LLVM.General.AST.Type.Operand

-- | An <a>Operand</a> is roughly anything that is an argument to an
--   <tt>Instruction</tt>
data Operand a
LocalReference :: ScalarType a -> Name a -> Operand a
ConstantOperand :: Constant a -> Operand a


module LLVM.General.AST.Type.Global

-- | Parameters for functions
data Parameter a
ScalarParameter :: ScalarType a -> Name a -> Parameter a
PtrParameter :: ScalarType a -> Name a -> Parameter (Ptr a)

-- | Attributes for the function call instruction
data FunctionAttribute
NoReturn :: FunctionAttribute
NoUnwind :: FunctionAttribute
ReadOnly :: FunctionAttribute
ReadNone :: FunctionAttribute
AlwaysInline :: FunctionAttribute

-- | Attribute groups are groups of attributes that are referenced by
--   objects within the IR. To use an attribute group, an object must
--   reference its GroupID.
data GroupID
GroupID :: !Word -> GroupID

-- | A global function definition
--   
--   Note that because we just use the reified dictionary structure of
--   Accelerate types, our functions are limited to operating over scalar
--   types only; no pointers to functions and nothing that returns void.
data GlobalFunction args t
Body :: Maybe (ScalarType r) -> Label -> GlobalFunction '[] r
Lam :: ScalarType a -> Operand a -> GlobalFunction args t -> GlobalFunction (a : args) t
data HList (l :: [*])
HNil :: HList '[]
HCons :: e -> HList l -> HList (e : l)


module LLVM.General.AST.Type.Instruction

-- | Predicate for comparison instruction
data Predicate
EQ :: Predicate
NE :: Predicate
LT :: Predicate
LE :: Predicate
GT :: Predicate
GE :: Predicate
data Volatile
Volatile :: Volatile
NonVolatile :: Volatile

-- | Non-terminating instructions
--   
--   <ul>
--   <li><a>http://llvm.org/docs/LangRef.html#binaryops</a></li>
--   <li><a>http://llvm.org/docs/LangRef.html#bitwiseops</a></li>
--   <li><a>http://llvm.org/docs/LangRef.html#memoryops</a></li>
--   <li><a>http://llvm.org/docs/LangRef.html#otherops</a></li>
--   </ul>
data Instruction a
Add :: NumType a -> Operand a -> Operand a -> Instruction a
Sub :: NumType a -> Operand a -> Operand a -> Instruction a
Mul :: NumType a -> Operand a -> Operand a -> Instruction a
Quot :: IntegralType a -> Operand a -> Operand a -> Instruction a
Rem :: IntegralType a -> Operand a -> Operand a -> Instruction a
Div :: FloatingType a -> Operand a -> Operand a -> Instruction a
ShiftL :: IntegralType a -> Operand a -> Operand a -> Instruction a
ShiftRL :: IntegralType a -> Operand a -> Operand a -> Instruction a
ShiftRA :: IntegralType a -> Operand a -> Operand a -> Instruction a
BAnd :: IntegralType a -> Operand a -> Operand a -> Instruction a
LAnd :: Operand Bool -> Operand Bool -> Instruction Bool
BOr :: IntegralType a -> Operand a -> Operand a -> Instruction a
LOr :: Operand Bool -> Operand Bool -> Instruction Bool
BXor :: IntegralType a -> Operand a -> Operand a -> Instruction a
LNot :: Operand Bool -> Instruction Bool
Load :: ScalarType a -> Volatile -> Operand (Ptr a) -> Instruction a
Store :: Volatile -> Operand (Ptr a) -> Operand a -> Instruction ()
GetElementPtr :: Operand a -> [Operand Int] -> Instruction (Ptr a)
Trunc :: BoundedType a -> BoundedType b -> Operand a -> Instruction b
FTrunc :: FloatingType a -> FloatingType b -> Operand a -> Instruction b
Ext :: BoundedType a -> BoundedType b -> Operand a -> Instruction b
FExt :: FloatingType a -> FloatingType b -> Operand a -> Instruction b
FPToInt :: FloatingType a -> IntegralType b -> Operand a -> Instruction b
IntToFP :: IntegralType a -> FloatingType b -> Operand a -> Instruction b
BitCast :: ScalarType b -> Operand a -> Instruction b
Cmp :: ScalarType a -> Predicate -> Operand a -> Operand a -> Instruction Bool
Phi :: ScalarType a -> [(Operand a, Label)] -> Instruction a
Call :: GlobalFunction args t -> [Either GroupID FunctionAttribute] -> Instruction t
Select :: ScalarType a -> Operand Bool -> Operand a -> Operand a -> Instruction a

-- | Instances of instructions may be given a name, allowing their results
--   to be referenced as Operands. Instructions returning void (e.g.
--   function calls) don't need names.
data Named ins a
(:=) :: Name a -> ins a -> Named ins a
Do :: ins () -> Named ins ()


module LLVM.General.AST.Type.Metadata

-- | <a>http://llvm.org/docs/LangRef.html#metadata</a>
--   
--   Metadata does not have a type, and is not a value.
data MetadataNode
MetadataNode :: [Maybe Metadata] -> MetadataNode
MetadataNodeReference :: MetadataNodeID -> MetadataNode
data Metadata
MetadataStringOperand :: String -> Metadata
MetadataOperand :: Operand a -> Metadata
MetadataNodeOperand :: MetadataNode -> Metadata


module Data.Array.Accelerate.LLVM.CodeGen.Type

-- | Does the concrete type represent signed or unsigned values?
class IsSigned dict where signed = not . unsigned unsigned = not . signed
signed :: IsSigned dict => dict a -> Bool
unsigned :: IsSigned dict => dict a -> Bool

-- | Extract the reified scalar type dictionary of an operation
class TypeOf op
typeOf :: TypeOf op => op a -> ScalarType a
instance Data.Array.Accelerate.LLVM.CodeGen.Type.IsSigned Data.Array.Accelerate.Type.ScalarType
instance Data.Array.Accelerate.LLVM.CodeGen.Type.IsSigned Data.Array.Accelerate.Type.BoundedType
instance Data.Array.Accelerate.LLVM.CodeGen.Type.IsSigned Data.Array.Accelerate.Type.NumType
instance Data.Array.Accelerate.LLVM.CodeGen.Type.IsSigned Data.Array.Accelerate.Type.IntegralType
instance Data.Array.Accelerate.LLVM.CodeGen.Type.IsSigned Data.Array.Accelerate.Type.FloatingType
instance Data.Array.Accelerate.LLVM.CodeGen.Type.IsSigned Data.Array.Accelerate.Type.NonNumType
instance Data.Array.Accelerate.LLVM.CodeGen.Type.TypeOf LLVM.General.AST.Type.Instruction.Instruction
instance Data.Array.Accelerate.LLVM.CodeGen.Type.TypeOf LLVM.General.AST.Type.Operand.Operand
instance Data.Array.Accelerate.LLVM.CodeGen.Type.TypeOf LLVM.General.AST.Type.Constant.Constant


module LLVM.General.AST.Type.Terminator

-- | <a>http://llvm.org/docs/LangRef.html#terminators</a>
--   
--   TLM: well, I don't think the types of these terminators make any
--   sense. When we branch, we are not propagating a particular value, just
--   moving the program counter, and anything we have declared already is
--   available for later computations. Maybe, we can make some of this
--   explicit in the <tt>phi</tt> node?
data Terminator a
Ret :: Terminator ()
RetVal :: Operand a -> Terminator a
Br :: Label -> Terminator ()
CondBr :: Operand Bool -> Label -> Label -> Terminator ()
Switch :: Operand a -> Label -> [(Constant a, Label)] -> Terminator ()


module Data.Array.Accelerate.LLVM.CodeGen.Module

-- | A compiled module consists of a number of global functions (kernels)
data Module arch aenv a
Module :: Module -> Module arch aenv a
[unModule] :: Module arch aenv a -> Module

-- | A fully-instantiated skeleton is a [collection of] kernel(s) that can
--   be compiled by LLVM into a global function that we can execute.
data Kernel arch aenv a
Kernel :: Global -> Kernel arch aenv a
[unKernel] :: Kernel arch aenv a -> Global


module Data.Array.Accelerate.LLVM.CodeGen.Intrinsic

-- | During code generation we need to know the name of functions
--   implementing certain intrinsic maths operations. Depending on the
--   backend, these functions may not be implemented using the standard C
--   math library.
--   
--   This class allows a backend to provide a mapping from the C math
--   library function name to the name of the function which should be
--   called instead. The default implementation maps to the llvm intrinsic.
--   For example:
--   
--   sqrtf -&gt; llvm.sqrt.f32 sqrt -&gt; llvm.sqrt.f64
class Intrinsic arch where intrinsicForTarget _ = llvmIntrinsic
intrinsicForTarget :: Intrinsic arch => arch -> HashMap String Label


module Data.Array.Accelerate.LLVM.CodeGen.IR

-- | The datatype <a>IR</a> represents the LLVM IR producing a value of
--   type <tt>a</tt>. Note that the operands comprising this value are
--   stored in representation type.
data IR t
IR :: Operands (EltRepr t) -> IR t

-- | Given some evidence that 'IR a' represents a scalar type, it can be
--   converted between the IR and Operand data types.
class IROP dict
op :: IROP dict => dict a -> IR a -> Operand a
ir :: IROP dict => dict a -> Operand a -> IR a
ir' :: IROP dict => dict a -> Operand a -> Operands a
op' :: IROP dict => dict a -> Operands a -> Operand a
instance Data.Array.Accelerate.LLVM.CodeGen.IR.IROP Data.Array.Accelerate.Type.ScalarType
instance Data.Array.Accelerate.LLVM.CodeGen.IR.IROP Data.Array.Accelerate.Type.NumType
instance Data.Array.Accelerate.LLVM.CodeGen.IR.IROP Data.Array.Accelerate.Type.IntegralType
instance Data.Array.Accelerate.LLVM.CodeGen.IR.IROP Data.Array.Accelerate.Type.FloatingType
instance Data.Array.Accelerate.LLVM.CodeGen.IR.IROP Data.Array.Accelerate.Type.NonNumType


module Data.Array.Accelerate.LLVM.CodeGen.Sugar

-- | LLVM IR is in single static assignment, so we need to be able to
--   generate fresh names for each application of a scalar function or
--   expression.
type IRExp arch aenv t = IROpenExp arch () aenv t
type IRFun1 arch aenv t = IROpenFun1 arch () aenv t
type IRFun2 arch aenv t = IROpenFun2 arch () aenv t
type IROpenExp arch env aenv t = CodeGen (IR t)
data IROpenFun1 arch env aenv t
IRFun1 :: (IR a -> IROpenExp arch (env, a) aenv b) -> IROpenFun1 arch env aenv (a -> b)
[app1] :: IROpenFun1 arch env aenv (a -> b) -> IR a -> IROpenExp arch (env, a) aenv b
data IROpenFun2 arch env aenv t
IRFun2 :: (IR a -> IR b -> IROpenExp arch ((env, a), b) aenv c) -> IROpenFun2 arch env aenv (a -> b -> c)
[app2] :: IROpenFun2 arch env aenv (a -> b -> c) -> IR a -> IR b -> IROpenExp arch ((env, a), b) aenv c
data IROpenAcc arch aenv arrs
IROpenAcc :: [Kernel arch aenv a] -> IROpenAcc arch aenv arrs
data IRDelayed arch aenv a
IRDelayed :: IRExp arch aenv sh -> IRFun1 arch aenv (sh -> e) -> IRFun1 arch aenv (Int -> e) -> IRDelayed arch aenv (Array sh e)
[delayedExtent] :: IRDelayed arch aenv (Array sh e) -> IRExp arch aenv sh
[delayedIndex] :: IRDelayed arch aenv (Array sh e) -> IRFun1 arch aenv (sh -> e)
[delayedLinearIndex] :: IRDelayed arch aenv (Array sh e) -> IRFun1 arch aenv (Int -> e)
data IRManifest arch aenv a
IRManifest :: Idx aenv arrs -> IRManifest arch aenv arrs
data IRArray a
IRArray :: IR sh -> IR e -> IRArray (Array sh e)
[irArrayShape] :: IRArray (Array sh e) -> IR sh
[irArrayData] :: IRArray (Array sh e) -> IR e


module Data.Array.Accelerate.LLVM.CodeGen.Environment

-- | An environment for local scalar expression bindings, encoded at the
--   value level as a heterogenous snoc list, and on the type level as
--   nested tuples.
data Val env
Empty :: Val ()
Push :: Val env -> IR t -> Val (env, t)

-- | Projection of a value from the valuation environment using a de Bruijn
--   index.
prj :: Idx env t -> Val env -> IR t

-- | A mapping between the environment index of a free array variable and
--   the Name of that array to be used in the generated code.
--   
--   This simply compresses the array indices into a continuous range,
--   rather than directly using the integer equivalent of the de Bruijn
--   index. Thus, the result is still sensitive to the order of let
--   bindings, but not of any intermediate (unused) free array variables.
type Gamma aenv = IntMap (Label, Idx' aenv)
data Idx' aenv
Idx' :: Idx aenv (Array sh e) -> Idx' aenv
aprj :: Idx aenv t -> Gamma aenv -> Name t

-- | Construct the array environment index, will be used by code generation
--   to map free array variable indices to names in the generated code.
makeGamma :: IntMap (Idx' aenv) -> Gamma aenv

-- | A free variable
freevar :: (Shape sh, Elt e) => Idx aenv (Array sh e) -> IntMap (Idx' aenv)


module Data.Array.Accelerate.LLVM.CodeGen.Constant

-- | Primitive constant values
primConst :: PrimConst t -> t

-- | A constant value
constant :: TupleType a -> a -> Operands a
scalar :: ScalarType a -> a -> Operand a
num :: NumType a -> a -> Operand a
integral :: IntegralType a -> a -> Operand a
floating :: FloatingType a -> a -> Operand a
nonnum :: NonNumType a -> a -> Operand a


module Data.Array.Accelerate.LLVM.CodeGen.Downcast

-- | Convert a value from our representation of the LLVM AST which uses
--   Haskell-level types, into the llvm-general representation where types
--   are represented only at the value level. We use the type-level
--   information to generate the appropriate value-level types.
class Downcast typed untyped
downcast :: Downcast typed untyped => typed -> untyped
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast a a' => Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast [a] [a']
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast a a' => Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (GHC.Base.Maybe a) (GHC.Base.Maybe a')
instance (Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast a a', Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast b b') => Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (a, b) (a', b')
instance (Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast a a', Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast b b') => Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (Data.Either.Either a b) (Data.Either.Either a' b')
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast LLVM.General.AST.Type.Flags.NUW GHC.Types.Bool
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast LLVM.General.AST.Type.Flags.NSW GHC.Types.Bool
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast LLVM.General.AST.Instruction.FastMathFlags LLVM.General.AST.Instruction.FastMathFlags
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (LLVM.General.AST.Type.Name.Name a) LLVM.General.AST.Name.Name
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (LLVM.General.AST.Type.Instruction.Instruction a) LLVM.General.AST.Instruction.Instruction
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast LLVM.General.AST.Type.Instruction.Volatile GHC.Types.Bool
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (i a) i' => Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (LLVM.General.AST.Type.Instruction.Named i a) (LLVM.General.AST.Instruction.Named i')
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast a b => Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (LLVM.General.AST.Instruction.Named a) (LLVM.General.AST.Instruction.Named b)
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (LLVM.General.AST.Type.Constant.Constant a) LLVM.General.AST.Constant.Constant
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (LLVM.General.AST.Type.Operand.Operand a) LLVM.General.AST.Operand.Operand
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast LLVM.General.AST.Type.Metadata.Metadata LLVM.General.AST.Operand.Operand
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast LLVM.General.AST.Type.Metadata.MetadataNode LLVM.General.AST.Operand.MetadataNode
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (LLVM.General.AST.Type.Terminator.Terminator a) LLVM.General.AST.Instruction.Terminator
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast LLVM.General.AST.Type.Name.Label LLVM.General.AST.Name.Name
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (LLVM.General.AST.Type.Global.Parameter a) LLVM.General.AST.Global.Parameter
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (LLVM.General.AST.Type.Global.GlobalFunction args t) LLVM.General.AST.Operand.CallableOperand
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (LLVM.General.AST.Type.Global.GlobalFunction args t) [(LLVM.General.AST.Operand.Operand, [LLVM.General.AST.ParameterAttribute.ParameterAttribute])]
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (LLVM.General.AST.Type.Global.GlobalFunction args t) LLVM.General.AST.Global.Global
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast LLVM.General.AST.Type.Global.FunctionAttribute LLVM.General.AST.FunctionAttribute.FunctionAttribute
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast LLVM.General.AST.Type.Global.GroupID LLVM.General.AST.FunctionAttribute.GroupID
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (dict a) LLVM.General.AST.Type.Type => Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (GHC.Base.Maybe (dict a)) LLVM.General.AST.Type.Type
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (Data.Array.Accelerate.Type.ScalarType a) LLVM.General.AST.Type.Type
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (Data.Array.Accelerate.Type.BoundedType t) LLVM.General.AST.Type.Type
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (Data.Array.Accelerate.Type.NumType a) LLVM.General.AST.Type.Type
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (Data.Array.Accelerate.Type.IntegralType a) LLVM.General.AST.Type.Type
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (Data.Array.Accelerate.Type.FloatingType a) LLVM.General.AST.Type.Type
instance Data.Array.Accelerate.LLVM.CodeGen.Downcast.Downcast (Data.Array.Accelerate.Type.NonNumType a) LLVM.General.AST.Type.Type


module Data.Array.Accelerate.LLVM.Target

-- | Describes some target specific information needed for code generation
class Target t
targetTriple :: Target t => t -> Maybe String
targetDataLayout :: Target t => t -> Maybe DataLayout


module Data.Array.Accelerate.LLVM.CodeGen.Monad
data CodeGen a
runLLVM :: (Target arch, Intrinsic arch) => CodeGen (IROpenAcc arch aenv a) -> Module arch aenv a

-- | Generate a fresh local reference
fresh :: Elt a => CodeGen (IR a)

-- | Add a global declaration to the symbol table
declare :: Global -> CodeGen ()

-- | Get name of the corresponding intrinsic function implementing a given
--   C function. If there is no mapping, the C function name is used.
intrinsic :: String -> CodeGen Label
data Block

-- | Create a new basic block, but don't yet add it to the block chain. You
--   need to call <a>setBlock</a> to append it to the chain, so that
--   subsequent instructions are added to this block.
--   
--   Note: [Basic blocks]
--   
--   The names of basic blocks are generated based on the base name
--   provided to the <a>newBlock</a> function, as well as the current state
--   (length) of the block stream. By not immediately adding new blocks to
--   the stream, we have the advantage that:
--   
--   <ol>
--   <li>Instructions are generated "in order", and are always appended to
--   the stream. There is no need to search the stream for a block of the
--   right name.</li>
--   <li>Blocks are named in groups, which helps readability. For example,
--   the blocks for the then and else branches of a conditional, created at
--   the same time, will be named similarly: 'if4.then' and 'if4.else',
--   etc.</li>
--   </ol>
--   
--   However, this leads to a slight awkwardness when walking the AST.
--   Since a new naming group scheme is only applied *after* a call to
--   <a>setBlock</a>, encountering (say) nested conditionals in the walk
--   will generate logically distinct blocks that happen to have the same
--   name. This means that instructions might be added to the wrong blocks,
--   or the first set of blocks will be emitted empty and/or without a
--   terminator.
newBlock :: String -> CodeGen Block

-- | Add this block to the block stream. Any instructions pushed onto the
--   stream by <a>instr</a> and friends will now apply to this block.
setBlock :: Block -> CodeGen ()

-- | Generate a new block and branch unconditionally to it.
beginBlock :: String -> CodeGen Block

-- | Extract the block state and construct the basic blocks that form a
--   function body. The block stream is re-initialised, but module-level
--   state such as the global symbol table is left intact.
createBlocks :: CodeGen [BasicBlock]

-- | Add an instruction to the state of the currently active block so that
--   it is computed, and return the operand (LocalReference) that can be
--   used to later refer to it.
instr :: Instruction a -> CodeGen (IR a)
instr' :: Instruction a -> CodeGen (Operand a)

-- | Execute an unnamed instruction
do_ :: Instruction () -> CodeGen ()

-- | Return void from a basic block
return_ :: CodeGen ()

-- | Return a value from a basic block
retval_ :: Operand a -> CodeGen ()

-- | Unconditional branch. Return the name of the block that was branched
--   from.
br :: Block -> CodeGen Block

-- | Conditional branch. Return the name of the block that was branched
--   from.
cbr :: IR Bool -> Block -> Block -> CodeGen Block

-- | Add a phi node to the top of the current block
phi :: Elt a => [(IR a, Block)] -> CodeGen (IR a)
phi' :: Elt a => Block -> IR a -> [(IR a, Block)] -> CodeGen (IR a)

-- | Insert a metadata key/value pair into the current module.
addMetadata :: String -> [Maybe Metadata] -> CodeGen ()
instance Control.Monad.State.Class.MonadState Data.Array.Accelerate.LLVM.CodeGen.Monad.CodeGenState Data.Array.Accelerate.LLVM.CodeGen.Monad.CodeGen
instance GHC.Base.Monad Data.Array.Accelerate.LLVM.CodeGen.Monad.CodeGen
instance GHC.Base.Applicative Data.Array.Accelerate.LLVM.CodeGen.Monad.CodeGen
instance GHC.Base.Functor Data.Array.Accelerate.LLVM.CodeGen.Monad.CodeGen


module Data.Array.Accelerate.LLVM.CodeGen.Base

-- | Objects of various sorts in LLVM IR are identified by address in the
--   LLVM C++ API, and may be given a string name. When printed to (resp.
--   read from) human-readable LLVM assembly, objects without string names
--   are numbered sequentially (resp. must be numbered sequentially).
--   String names may be quoted, and are quoted when printed if they would
--   otherwise be misread - e.g. when containing special characters.
--   
--   <pre>
--   7
--   </pre>
--   
--   means the seventh unnamed object, while
--   
--   <pre>
--   "7"
--   </pre>
--   
--   means the object named with the string "7".
--   
--   This libraries handling of <a>UnName</a>s during translation of the
--   AST down into C++ IR is somewhat more forgiving than the LLVM assembly
--   parser: it does not require that unnamed values be numbered
--   sequentially; however, the numbers of <a>UnName</a>s passed into C++
--   cannot be preserved in the C++ objects. If the C++ IR is printed as
--   assembly or translated into a Haskell AST, unnamed nodes will be
--   renumbered sequentially. Thus unnamed node numbers should be thought
--   of as having any scope limited to the <a>Module</a> in which they are
--   used.
data Name a

-- | a string name
Name :: String -> Name a

-- | a number for a nameless thing
UnName :: Word -> Name a
local :: ScalarType a -> Name a -> IR a
global :: ScalarType a -> Name a -> IR a

-- | Names of array data elements
irArray :: (Shape sh, Elt e) => Name (Array sh e) -> IRArray (Array sh e)

-- | Generate typed local names for array data components as well as
--   function parameters to bind those names
mutableArray :: (Shape sh, Elt e) => Name (Array sh e) -> (IRArray (Array sh e), [Parameter])

-- | Call a global function. The function declaration is inserted into the
--   symbol table.
call :: GlobalFunction args t -> [FunctionAttribute] -> CodeGen (IR t)
scalarParameter :: ScalarType t -> Name t -> Parameter
ptrParameter :: ScalarType t -> Name t -> Parameter

-- | Unpack the array environment into a set of input parameters to a
--   function. The environment here refers only to the actual free array
--   variables that are accessed by the function.
envParam :: Gamma aenv -> [Parameter]

-- | Generate function parameters for an Array with given base name.
arrayParam :: (Shape sh, Elt e) => Name (Array sh e) -> [Parameter]


module Data.Array.Accelerate.LLVM.CodeGen.Arithmetic
add :: NumType a -> IR a -> IR a -> CodeGen (IR a)
sub :: NumType a -> IR a -> IR a -> CodeGen (IR a)
mul :: NumType a -> IR a -> IR a -> CodeGen (IR a)
negate :: NumType a -> IR a -> CodeGen (IR a)
abs :: NumType a -> IR a -> CodeGen (IR a)
signum :: NumType a -> IR a -> CodeGen (IR a)
quot :: IntegralType a -> IR a -> IR a -> CodeGen (IR a)
rem :: IntegralType a -> IR a -> IR a -> CodeGen (IR a)
quotRem :: IntegralType a -> IR a -> IR a -> CodeGen (IR (a, a))
idiv :: IntegralType a -> IR a -> IR a -> CodeGen (IR a)
mod :: Elt a => IntegralType a -> IR a -> IR a -> CodeGen (IR a)
divMod :: IntegralType a -> IR a -> IR a -> CodeGen (IR (a, a))
band :: IntegralType a -> IR a -> IR a -> CodeGen (IR a)
bor :: IntegralType a -> IR a -> IR a -> CodeGen (IR a)
xor :: IntegralType a -> IR a -> IR a -> CodeGen (IR a)
complement :: IntegralType a -> IR a -> CodeGen (IR a)
shiftL :: IntegralType a -> IR a -> IR Int -> CodeGen (IR a)
shiftR :: IntegralType a -> IR a -> IR Int -> CodeGen (IR a)
shiftRL :: IntegralType a -> IR a -> IR Int -> CodeGen (IR a)
shiftRA :: IntegralType a -> IR a -> IR Int -> CodeGen (IR a)
rotateL :: IntegralType a -> IR a -> IR Int -> CodeGen (IR a)
rotateR :: IntegralType a -> IR a -> IR Int -> CodeGen (IR a)
fdiv :: FloatingType a -> IR a -> IR a -> CodeGen (IR a)
recip :: FloatingType a -> IR a -> CodeGen (IR a)
sin :: FloatingType a -> IR a -> CodeGen (IR a)
cos :: FloatingType a -> IR a -> CodeGen (IR a)
tan :: FloatingType a -> IR a -> CodeGen (IR a)
sinh :: FloatingType a -> IR a -> CodeGen (IR a)
cosh :: FloatingType a -> IR a -> CodeGen (IR a)
tanh :: FloatingType a -> IR a -> CodeGen (IR a)
asin :: FloatingType a -> IR a -> CodeGen (IR a)
acos :: FloatingType a -> IR a -> CodeGen (IR a)
atan :: FloatingType a -> IR a -> CodeGen (IR a)
asinh :: FloatingType a -> IR a -> CodeGen (IR a)
acosh :: FloatingType a -> IR a -> CodeGen (IR a)
atanh :: FloatingType a -> IR a -> CodeGen (IR a)
atan2 :: FloatingType a -> IR a -> IR a -> CodeGen (IR a)
exp :: FloatingType a -> IR a -> CodeGen (IR a)
fpow :: FloatingType a -> IR a -> IR a -> CodeGen (IR a)
sqrt :: FloatingType a -> IR a -> CodeGen (IR a)
log :: FloatingType a -> IR a -> CodeGen (IR a)
logBase :: FloatingType a -> IR a -> IR a -> CodeGen (IR a)
isNaN :: FloatingType a -> IR a -> CodeGen (IR Bool)
truncate :: FloatingType a -> IntegralType b -> IR a -> CodeGen (IR b)
round :: FloatingType a -> IntegralType b -> IR a -> CodeGen (IR b)
floor :: FloatingType a -> IntegralType b -> IR a -> CodeGen (IR b)
ceiling :: FloatingType a -> IntegralType b -> IR a -> CodeGen (IR b)
cmp :: Predicate -> ScalarType a -> IR a -> IR a -> CodeGen (IR Bool)
lt :: ScalarType a -> IR a -> IR a -> CodeGen (IR Bool)
gt :: ScalarType a -> IR a -> IR a -> CodeGen (IR Bool)
lte :: ScalarType a -> IR a -> IR a -> CodeGen (IR Bool)
gte :: ScalarType a -> IR a -> IR a -> CodeGen (IR Bool)
eq :: ScalarType a -> IR a -> IR a -> CodeGen (IR Bool)
neq :: ScalarType a -> IR a -> IR a -> CodeGen (IR Bool)
max :: ScalarType a -> IR a -> IR a -> CodeGen (IR a)
min :: ScalarType a -> IR a -> IR a -> CodeGen (IR a)
land :: IR Bool -> IR Bool -> CodeGen (IR Bool)
lor :: IR Bool -> IR Bool -> CodeGen (IR Bool)
lnot :: IR Bool -> CodeGen (IR Bool)
ord :: IR Char -> CodeGen (IR Int)
chr :: IR Int -> CodeGen (IR Char)
boolToInt :: IR Bool -> CodeGen (IR Int)
fromIntegral :: IntegralType a -> NumType b -> IR a -> CodeGen (IR b)
toFloating :: NumType a -> FloatingType b -> IR a -> CodeGen (IR b)
coerce :: ScalarType a -> ScalarType b -> IR a -> CodeGen (IR b)
fst :: IR (a, b) -> IR a
snd :: IR (a, b) -> IR b
pair :: IR a -> IR b -> IR (a, b)
unpair :: IR (a, b) -> (IR a, IR b)
uncurry :: (IR a -> IR b -> c) -> IR (a, b) -> c
binop :: IROP dict => (dict a -> Operand a -> Operand a -> Instruction a) -> dict a -> IR a -> IR a -> CodeGen (IR a)
ifThenElse :: Elt a => CodeGen (IR Bool) -> CodeGen (IR a) -> CodeGen (IR a) -> CodeGen (IR a)
mathf :: String -> FloatingType t -> IR t -> CodeGen (IR t)
mathf' :: String -> FloatingType t -> IR t -> IR t -> CodeGen (IR t)
lm :: FloatingType t -> String -> CodeGen Label


module Data.Array.Accelerate.LLVM.CodeGen.Array

-- | Read a value from an array at the given index
readArray :: IRArray (Array sh e) -> IR Int -> CodeGen (IR e)

-- | Write a value into an array at the given index
writeArray :: IRArray (Array sh e) -> IR Int -> IR e -> CodeGen ()


module Data.Array.Accelerate.LLVM.CodeGen.Loop

-- | TODO: Iterate over a multidimensional index space.
--   
--   Build nested loops that iterate over a hype-rectangular index space
--   between the given coordinates. The LLVM optimiser will be able to
--   vectorise nested loops, including when we insert conversions to the
--   corresponding linear index (e.g., in order to index arrays).
--   
--   iterate :: Shape sh =&gt; IR sh -- ^ starting index -&gt; IR sh -- ^
--   final index -&gt; (IR sh -&gt; CodeGen (IR a)) -- ^ body of the loop
--   -&gt; CodeGen (IR a) iterate from to body = error
--   "CodeGen.Loop.iterate"
--   
--   A standard <a>for</a> loop.
for :: (Elt i, IsIntegral i) => IR i -> (IR i -> CodeGen (IR Bool)) -> (IR i -> CodeGen (IR i)) -> (IR i -> CodeGen ()) -> CodeGen ()

-- | An loop with iteration count and accumulator.
iter :: (Elt i, IsIntegral i, Elt a) => IR i -> IR a -> (IR i -> CodeGen (IR Bool)) -> (IR i -> CodeGen (IR i)) -> (IR i -> IR a -> CodeGen (IR a)) -> CodeGen (IR a)

-- | A standard <a>while</a> loop
while :: Elt a => (IR a -> CodeGen (IR Bool)) -> (IR a -> CodeGen (IR a)) -> IR a -> CodeGen (IR a)


module Data.Array.Accelerate.LLVM.CodeGen.Exp

-- | A class covering code generation for a subset of the scalar
--   operations. All operations (except Foreign) have a default instance,
--   but this allows a backend to specialise the implementation for the
--   more complex operations.
class Expression arch where eforeign = \ format_a1rW2 kind_a1rW3 fn_a1rW4 msg_a1rW5 -> error (format_a1rW2 kind_a1rW3 (call fn_a1rW4 msg_a1rW5)) (\ kind_a1rW6 msg_a1rW7 -> message kind_a1rW6 ("Data/Array/Accelerate/LLVM/CodeGen/Exp.hs:57:14: " ++ msg_a1rW7)) Internal "eforeign" "default instance not implemented yet" while p f x = while (app1 p) (app1 f) =<< x
eforeign :: (Expression arch, Foreign f, Elt x, Elt y) => arch -> f x y -> IRFun1 arch () (x -> y) -> IROpenExp arch env aenv x -> IROpenExp arch env aenv y
while :: (Expression arch, Elt a) => IROpenFun1 arch env aenv (a -> Bool) -> IROpenFun1 arch env aenv (a -> a) -> IROpenExp arch env aenv a -> IROpenExp arch env aenv a
llvmOfFun1 :: Expression arch => arch -> DelayedFun aenv (a -> b) -> Gamma aenv -> IRFun1 arch aenv (a -> b)
llvmOfFun2 :: Expression arch => arch -> DelayedFun aenv (a -> b -> c) -> Gamma aenv -> IRFun2 arch aenv (a -> b -> c)

-- | Convert an open scalar expression into a sequence of LLVM IR
--   instructions. Code is generated in depth first order, and uses a monad
--   to collect the sequence of instructions used to construct basic
--   blocks.
llvmOfOpenExp :: Expression arch => arch -> DelayedOpenExp env aenv _t -> Val env -> Gamma aenv -> IROpenExp arch env aenv _t

-- | Convert a multidimensional array index into a linear index
intOfIndex :: Shape sh => IR sh -> IR sh -> CodeGen (IR Int)

-- | Convert a linear index into into a multidimensional index
indexOfInt :: Shape sh => IR sh -> IR Int -> CodeGen (IR sh)

-- | Generate llvm operations for primitive scalar functions
llvmOfPrimFun :: (Elt a, Elt r) => PrimFun (a -> r) -> IR a -> CodeGen (IR r)


module Data.Array.Accelerate.LLVM.CodeGen.Stencil
stencilAccess :: Stencil sh e stencil => Boundary (IR e) -> IRArray (Array sh e) -> IR sh -> CodeGen (IR stencil)
bounded :: (Shape sh, Elt e) => Boundary (IR e) -> IRArray (Array sh e) -> IR sh -> CodeGen (IR e)
int :: Int -> IR Int
bool :: Bool -> IR Bool
unindex :: IR (sh :. Int) -> IR sh :. IR Int
index :: IR sh -> IR Int -> IR (sh :. Int)
tup3 :: IR a -> IR b -> IR c -> IR (a, b, c)
tup5 :: IR a -> IR b -> IR c -> IR d -> IR e -> IR (a, b, c, d, e)
tup7 :: IR a -> IR b -> IR c -> IR d -> IR e -> IR f -> IR g -> IR (a, b, c, d, e, f, g)
tup9 :: IR a -> IR b -> IR c -> IR d -> IR e -> IR f -> IR g -> IR h -> IR i -> IR (a, b, c, d, e, f, g, h, i)
cons :: Shape sh => IR Int -> IR sh -> IR (sh :. Int)
uncons :: Shape sh => IR (sh :. Int) -> (IR Int, IR sh)


module Data.Array.Accelerate.LLVM.CodeGen.Skeleton

-- | A class covering code generation for all of the primitive array
--   operations. Client backends implement an instance of this class.
--   
--   Minimal complete definition: * generate * fold, fold1, foldSeg,
--   fold1Seg * scanl, scanl', scanl1, scanr, scanr', scanr1 * permute
class Skeleton arch where map = defaultMap backpermute = defaultBackpermute transform = defaultTransform stencil = defaultStencil1 stencil2 = defaultStencil2
generate :: (Skeleton arch, Shape sh, Elt e) => arch -> Gamma aenv -> IRFun1 arch aenv (sh -> e) -> CodeGen (IROpenAcc arch aenv (Array sh e))
transform :: (Skeleton arch, Shape sh, Shape sh', Elt a, Elt b) => arch -> Gamma aenv -> IRFun1 arch aenv (sh' -> sh) -> IRFun1 arch aenv (a -> b) -> IRDelayed arch aenv (Array sh a) -> CodeGen (IROpenAcc arch aenv (Array sh' b))
map :: (Skeleton arch, Shape sh, Elt a, Elt b) => arch -> Gamma aenv -> IRFun1 arch aenv (a -> b) -> IRDelayed arch aenv (Array sh a) -> CodeGen (IROpenAcc arch aenv (Array sh b))
fold :: (Skeleton arch, Shape sh, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRExp arch aenv e -> IRDelayed arch aenv (Array (sh :. Int) e) -> CodeGen (IROpenAcc arch aenv (Array sh e))
fold1 :: (Skeleton arch, Shape sh, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRDelayed arch aenv (Array (sh :. Int) e) -> CodeGen (IROpenAcc arch aenv (Array sh e))
foldSeg :: (Skeleton arch, Shape sh, Elt e, Elt i, IsIntegral i) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRExp arch aenv e -> IRDelayed arch aenv (Array (sh :. Int) e) -> IRDelayed arch aenv (Segments i) -> CodeGen (IROpenAcc arch aenv (Array (sh :. Int) e))
fold1Seg :: (Skeleton arch, Shape sh, Elt e, Elt i, IsIntegral i) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRDelayed arch aenv (Array (sh :. Int) e) -> IRDelayed arch aenv (Segments i) -> CodeGen (IROpenAcc arch aenv (Array (sh :. Int) e))
scanl :: (Skeleton arch, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRExp arch aenv e -> IRDelayed arch aenv (Vector e) -> CodeGen (IROpenAcc arch aenv (Vector e))
scanl' :: (Skeleton arch, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRExp arch aenv e -> IRDelayed arch aenv (Vector e) -> CodeGen (IROpenAcc arch aenv (Vector e, Scalar e))
scanl1 :: (Skeleton arch, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRDelayed arch aenv (Vector e) -> CodeGen (IROpenAcc arch aenv (Vector e))
scanr :: (Skeleton arch, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRExp arch aenv e -> IRDelayed arch aenv (Vector e) -> CodeGen (IROpenAcc arch aenv (Vector e))
scanr' :: (Skeleton arch, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRExp arch aenv e -> IRDelayed arch aenv (Vector e) -> CodeGen (IROpenAcc arch aenv (Vector e, Scalar e))
scanr1 :: (Skeleton arch, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRDelayed arch aenv (Vector e) -> CodeGen (IROpenAcc arch aenv (Vector e))
permute :: (Skeleton arch, Shape sh, Shape sh', Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRFun1 arch aenv (sh -> sh') -> IRDelayed arch aenv (Array sh e) -> CodeGen (IROpenAcc arch aenv (Array sh' e))
backpermute :: (Skeleton arch, Shape sh, Shape sh', Elt e) => arch -> Gamma aenv -> IRFun1 arch aenv (sh' -> sh) -> IRDelayed arch aenv (Array sh e) -> CodeGen (IROpenAcc arch aenv (Array sh' e))
stencil :: (Skeleton arch, Elt a, Elt b, Stencil sh a stencil) => arch -> Gamma aenv -> IRFun1 arch aenv (stencil -> b) -> Boundary (IR a) -> IRManifest arch aenv (Array sh a) -> CodeGen (IROpenAcc arch aenv (Array sh b))
stencil2 :: (Skeleton arch, Elt a, Elt b, Elt c, Stencil sh a stencil1, Stencil sh b stencil2) => arch -> Gamma aenv -> IRFun2 arch aenv (stencil1 -> stencil2 -> c) -> Boundary (IR a) -> IRManifest arch aenv (Array sh a) -> Boundary (IR b) -> IRManifest arch aenv (Array sh b) -> CodeGen (IROpenAcc arch aenv (Array sh c))


module Data.Array.Accelerate.LLVM.CodeGen

-- | A class covering code generation for all of the primitive array
--   operations. Client backends implement an instance of this class.
--   
--   Minimal complete definition: * generate * fold, fold1, foldSeg,
--   fold1Seg * scanl, scanl', scanl1, scanr, scanr', scanr1 * permute
class Skeleton arch where map = defaultMap backpermute = defaultBackpermute transform = defaultTransform stencil = defaultStencil1 stencil2 = defaultStencil2
generate :: (Skeleton arch, Shape sh, Elt e) => arch -> Gamma aenv -> IRFun1 arch aenv (sh -> e) -> CodeGen (IROpenAcc arch aenv (Array sh e))
transform :: (Skeleton arch, Shape sh, Shape sh', Elt a, Elt b) => arch -> Gamma aenv -> IRFun1 arch aenv (sh' -> sh) -> IRFun1 arch aenv (a -> b) -> IRDelayed arch aenv (Array sh a) -> CodeGen (IROpenAcc arch aenv (Array sh' b))
map :: (Skeleton arch, Shape sh, Elt a, Elt b) => arch -> Gamma aenv -> IRFun1 arch aenv (a -> b) -> IRDelayed arch aenv (Array sh a) -> CodeGen (IROpenAcc arch aenv (Array sh b))
fold :: (Skeleton arch, Shape sh, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRExp arch aenv e -> IRDelayed arch aenv (Array (sh :. Int) e) -> CodeGen (IROpenAcc arch aenv (Array sh e))
fold1 :: (Skeleton arch, Shape sh, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRDelayed arch aenv (Array (sh :. Int) e) -> CodeGen (IROpenAcc arch aenv (Array sh e))
foldSeg :: (Skeleton arch, Shape sh, Elt e, Elt i, IsIntegral i) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRExp arch aenv e -> IRDelayed arch aenv (Array (sh :. Int) e) -> IRDelayed arch aenv (Segments i) -> CodeGen (IROpenAcc arch aenv (Array (sh :. Int) e))
fold1Seg :: (Skeleton arch, Shape sh, Elt e, Elt i, IsIntegral i) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRDelayed arch aenv (Array (sh :. Int) e) -> IRDelayed arch aenv (Segments i) -> CodeGen (IROpenAcc arch aenv (Array (sh :. Int) e))
scanl :: (Skeleton arch, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRExp arch aenv e -> IRDelayed arch aenv (Vector e) -> CodeGen (IROpenAcc arch aenv (Vector e))
scanl' :: (Skeleton arch, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRExp arch aenv e -> IRDelayed arch aenv (Vector e) -> CodeGen (IROpenAcc arch aenv (Vector e, Scalar e))
scanl1 :: (Skeleton arch, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRDelayed arch aenv (Vector e) -> CodeGen (IROpenAcc arch aenv (Vector e))
scanr :: (Skeleton arch, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRExp arch aenv e -> IRDelayed arch aenv (Vector e) -> CodeGen (IROpenAcc arch aenv (Vector e))
scanr' :: (Skeleton arch, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRExp arch aenv e -> IRDelayed arch aenv (Vector e) -> CodeGen (IROpenAcc arch aenv (Vector e, Scalar e))
scanr1 :: (Skeleton arch, Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRDelayed arch aenv (Vector e) -> CodeGen (IROpenAcc arch aenv (Vector e))
permute :: (Skeleton arch, Shape sh, Shape sh', Elt e) => arch -> Gamma aenv -> IRFun2 arch aenv (e -> e -> e) -> IRFun1 arch aenv (sh -> sh') -> IRDelayed arch aenv (Array sh e) -> CodeGen (IROpenAcc arch aenv (Array sh' e))
backpermute :: (Skeleton arch, Shape sh, Shape sh', Elt e) => arch -> Gamma aenv -> IRFun1 arch aenv (sh' -> sh) -> IRDelayed arch aenv (Array sh e) -> CodeGen (IROpenAcc arch aenv (Array sh' e))
stencil :: (Skeleton arch, Elt a, Elt b, Stencil sh a stencil) => arch -> Gamma aenv -> IRFun1 arch aenv (stencil -> b) -> Boundary (IR a) -> IRManifest arch aenv (Array sh a) -> CodeGen (IROpenAcc arch aenv (Array sh b))
stencil2 :: (Skeleton arch, Elt a, Elt b, Elt c, Stencil sh a stencil1, Stencil sh b stencil2) => arch -> Gamma aenv -> IRFun2 arch aenv (stencil1 -> stencil2 -> c) -> Boundary (IR a) -> IRManifest arch aenv (Array sh a) -> Boundary (IR b) -> IRManifest arch aenv (Array sh b) -> CodeGen (IROpenAcc arch aenv (Array sh c))

-- | A class covering code generation for a subset of the scalar
--   operations. All operations (except Foreign) have a default instance,
--   but this allows a backend to specialise the implementation for the
--   more complex operations.
class Expression arch where eforeign = \ format_a1rW2 kind_a1rW3 fn_a1rW4 msg_a1rW5 -> error (format_a1rW2 kind_a1rW3 (call fn_a1rW4 msg_a1rW5)) (\ kind_a1rW6 msg_a1rW7 -> message kind_a1rW6 ("Data/Array/Accelerate/LLVM/CodeGen/Exp.hs:57:14: " ++ msg_a1rW7)) Internal "eforeign" "default instance not implemented yet" while p f x = while (app1 p) (app1 f) =<< x
eforeign :: (Expression arch, Foreign f, Elt x, Elt y) => arch -> f x y -> IRFun1 arch () (x -> y) -> IROpenExp arch env aenv x -> IROpenExp arch env aenv y
while :: (Expression arch, Elt a) => IROpenFun1 arch env aenv (a -> Bool) -> IROpenFun1 arch env aenv (a -> a) -> IROpenExp arch env aenv a -> IROpenExp arch env aenv a

-- | During code generation we need to know the name of functions
--   implementing certain intrinsic maths operations. Depending on the
--   backend, these functions may not be implemented using the standard C
--   math library.
--   
--   This class allows a backend to provide a mapping from the C math
--   library function name to the name of the function which should be
--   called instead. The default implementation maps to the llvm intrinsic.
--   For example:
--   
--   sqrtf -&gt; llvm.sqrt.f32 sqrt -&gt; llvm.sqrt.f64
class Intrinsic arch where intrinsicForTarget _ = llvmIntrinsic
intrinsicForTarget :: Intrinsic arch => arch -> HashMap String Label

-- | Generate code for a given target architecture.
llvmOfOpenAcc :: (Target arch, Skeleton arch, Intrinsic arch, Expression arch) => arch -> DelayedOpenAcc aenv arrs -> Gamma aenv -> Module arch aenv arrs


module Data.Array.Accelerate.LLVM.Array.Nursery

-- | The nursery is primarily designed as a place to store device memory
--   arrays that are no longer needed. Often it is quicker to reuse an
--   existing array, rather than calling into the device API in order to
--   allocate a fresh array.
--   
--   The nursery is wrapped in an MVar so that several threads may safely
--   access it concurrently.
data Nursery a
Nursery :: {-# UNPACK #-} !(NRS a) -> {-# UNPACK #-} !(Weak (NRS a)) -> Nursery a
type NRS a = MVar (IntMap (Seq a))

-- | Create a fresh nursery
--   
--   When the nursery is garbage collected, the provided function will be
--   run on each element of the map. In the context of array storage, this
--   would be to free the stashed memory.
new :: (a -> IO ()) -> IO (Nursery a)

-- | Look up an entry in the nursery with a given key.
lookup :: Int -> Nursery a -> IO (Maybe a)

-- | Add an entry into the nursery
insert :: Int -> a -> NRS a -> IO ()

-- | Delete all entries from the nursery.
cleanup :: (a -> IO ()) -> NRS a -> IO ()
trace :: String -> IO a -> IO a
message :: String -> IO ()


module Data.Array.Accelerate.LLVM.Array.Table

-- | The memory table is used to associate a host-side Accelerate array
--   with a corresponding array in on a remote target.
--   
--   Old entries in the table are garbage collected from the table once the
--   host array is no longer reachable on the heap. The table stores weak
--   references to its entries. Once the key becomes unreachable, a
--   finaliser will fire and remove this entry from the table, and further
--   attempts to dereference the weak pointer will fail.
--   
--   PRECONDITION: The underlying Accelerate array is pinned.
data MemoryTable c
type MallocRemote c a = Int -> IO (c a)
type FreeRemote c = forall a. c a -> IO ()

-- | Create a new memory table from host to remote arrays. When the
--   structure is collected it will finalise all entries in the table.
new :: FreeRemote c -> IO (MemoryTable c)

-- | Is the key a _valid_ member of the memory table?
--   
--   Because of the possibility of collisions in the host key, this also
--   ensures that the entries still refers to valid data. If not, we run
--   the finaliser, which also deallocates the remote data and removes its
--   entry from the table. Note that it is important for the main thread to
--   <a>yield</a> at that point so that the finaliser can run immediately.
--   
--   See: [Host arrays as memory table keys]
member :: (ArrayElt e, ArrayPtrs e ~ Ptr a) => MemoryTable c -> ArrayData e -> IO Bool

-- | Lookup the remote array corresponding to the given host-side array.
--   This assumes that all key-value pairs in the memory table refer to
--   valid data. If you are not sure, or want to check whether there is a
--   remote array for the given key, use <a>member</a> instead.
--   
--   See note: [Host arrays as memory table keys].
lookup :: (ArrayElt e, ArrayPtrs e ~ Ptr a, Typeable b) => MemoryTable c -> ArrayData e -> IO (Maybe (c b))

-- | Allocate a new remote array and associate it with the given host side
--   array. This will attempt to reuse an old array from the nursery if
--   possible.
--   
--   In order to increase the hit rate to the nursery, allocations are not
--   made for the exact number of bytes requested, but instead rounded up
--   to a chunk/page size.
malloc :: (ArrayElt e, ArrayPtrs e ~ Ptr a, Typeable a, Storable a) => FreeRemote c -> MallocRemote c a -> MemoryTable c -> ArrayData e -> Int -> IO (c a)

-- | Cleanup the memory table in an attempt to create more free space on
--   the remote device. This removes all entries from the nursery, and
--   finalises any unreachable arrays.
cleanup :: FreeRemote c -> MemoryTable c -> IO ()


module Data.Array.Accelerate.LLVM.State

-- | The LLVM monad, for executing array computations. This consists of a
--   stack for the LLVM execution context as well as the per-execution
--   target specific state <tt>target</tt>.
newtype LLVM target a
LLVM :: StateT target IO a -> LLVM target a
[runLLVM] :: LLVM target a -> StateT target IO a

-- | Extract the execution state: 'gets llvmTarget'
llvmTarget :: t -> t

-- | Evaluate the given target with an LLVM context
evalLLVM :: t -> LLVM t a -> IO a

-- | Make sure the GC knows that we want to keep this thing alive forever.
--   
--   We may want to introduce some way to actually shut this down if, for
--   example, the object has not been accessed in a while (whatever that
--   means).
--   
--   Broken in ghci-7.6.1 Mac OS X due to bug #7299.
keepAlive :: a -> IO a
instance Control.Monad.Catch.MonadMask (Data.Array.Accelerate.LLVM.State.LLVM target)
instance Control.Monad.Catch.MonadCatch (Data.Array.Accelerate.LLVM.State.LLVM target)
instance Control.Monad.Catch.MonadThrow (Data.Array.Accelerate.LLVM.State.LLVM target)
instance Control.Monad.State.Class.MonadState target (Data.Array.Accelerate.LLVM.State.LLVM target)
instance Control.Monad.IO.Class.MonadIO (Data.Array.Accelerate.LLVM.State.LLVM target)
instance GHC.Base.Monad (Data.Array.Accelerate.LLVM.State.LLVM target)
instance GHC.Base.Applicative (Data.Array.Accelerate.LLVM.State.LLVM target)
instance GHC.Base.Functor (Data.Array.Accelerate.LLVM.State.LLVM target)


module Data.Array.Accelerate.LLVM.Execute.Async

-- | The result of a potentially parallel computation which will be
--   available at some point (presumably, in the future). This is
--   essentially a write-once IVar.
data AsyncR arch a
AsyncR :: !(EventR arch) -> !a -> AsyncR arch a
class Async arch where type family StreamR arch type family EventR arch

-- | Create a new execution stream that can be used to track (potentially
--   parallel) computations
spawn :: Async arch => LLVM arch (StreamR arch)

-- | Generate a new event at the end of the given execution stream. It will
--   be filled once all prior work submitted to the stream has completed.
checkpoint :: Async arch => StreamR arch -> LLVM arch (EventR arch)

-- | Make all future work submitted to the given execution stream wait
--   until the given event has passed. Typically the event is from a
--   different execution stream, therefore this function is intended to
--   enable non-blocking cross-stream coordination.
after :: Async arch => StreamR arch -> EventR arch -> LLVM arch ()

-- | Block execution of the calling thread until the given event has been
--   recorded.
block :: Async arch => EventR arch -> LLVM arch ()

-- | Wait for an asynchronous operation to complete, then return it.
get :: Async arch => AsyncR arch a -> LLVM arch a

-- | Execute the given operation asynchronously in a new execution stream.
async :: Async arch => (StreamR arch -> LLVM arch a) -> LLVM arch (AsyncR arch a)


module Data.Array.Accelerate.LLVM.Execute.Environment
data AvalR arch env
Aempty :: AvalR arch ()
Apush :: AvalR arch env -> AsyncR arch t -> AvalR arch (env, t)
aprj :: Idx env t -> AvalR arch env -> AsyncR arch t


module Data.Array.Accelerate.LLVM.Execute.Marshal

-- | Convert function arguments into stream a form suitable for CUDA
--   function calls
marshal :: Marshalable t args => t -> StreamR t -> args -> IO [ArgR t]

-- | A type family that is used to specify a concrete kernel argument and
--   stream/context type for a given backend target.

-- | Data which can be marshalled as function arguments to kernels.
--   
--   These are just the basic definitions that don't require backend
--   specific knowledge. To complete the definition, a backend must provide
--   instances for:
--   
--   <ul>
--   <li>Int -- for shapes</li>
--   <li>ArrayData e -- for array data</li>
--   <li>(Gamma aenv, Aval aenv) -- for free array variables</li>
--   </ul>
class Marshalable t a
marshal' :: Marshalable t a => t -> StreamR t -> a -> IO (DList (ArgR t))
instance Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t ()
instance (Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t a, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t b) => Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t (a, b)
instance (Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t a, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t b, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t c) => Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t (a, b, c)
instance (Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t a, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t b, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t c, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t d) => Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t (a, b, c, d)
instance (Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t a, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t b, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t c, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t d, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t e) => Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t (a, b, c, d, e)
instance (Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t a, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t b, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t c, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t d, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t e, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t f) => Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t (a, b, c, d, e, f)
instance (Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t a, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t b, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t c, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t d, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t e, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t f, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t g) => Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t (a, b, c, d, e, f, g)
instance (Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t a, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t b, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t c, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t d, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t e, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t f, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t g, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t h) => Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t (a, b, c, d, e, f, g, h)
instance Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t a => Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t [a]
instance (Data.Array.Accelerate.Array.Sugar.Shape sh, Data.Array.Accelerate.Array.Sugar.Elt e, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t GHC.Types.Int, Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t (Data.Array.Accelerate.Array.Data.ArrayData (Data.Array.Accelerate.Array.Sugar.EltRepr e))) => Data.Array.Accelerate.LLVM.Execute.Marshal.Marshalable t (Data.Array.Accelerate.Array.Sugar.Array sh e)


module Data.Array.Accelerate.LLVM.Array.Data
class Async arch => Remote arch where allocateRemote sh = liftIO $ allocateArray sh useRemoteR _ _ _ = return () copyToRemoteR _ _ _ _ = return () copyToHostR _ _ _ _ = return () copyToPeerR _ _ _ _ _ = return () indexRemote (Array _ adata) i = return . toElt $! unsafeIndexArrayData adata i

-- | Allocate a new uninitialised array on the remote device.
allocateRemote :: (Remote arch, Shape sh, Elt e) => sh -> LLVM arch (Array sh e)

-- | Use the given immutable array on the remote device. Since the source
--   array is immutable, the allocator can evict and re-upload the data as
--   necessary without copy-back.
useRemoteR :: (Remote arch, ArrayElt e, ArrayPtrs e ~ Ptr a, Storable a, Typeable a, Typeable e) => Int -> Maybe (StreamR arch) -> ArrayData e -> LLVM arch ()

-- | Upload a section of an array from the host to the remote device. Only
--   the elements between the given indices (inclusive left, exclusive
--   right) are transferred.
copyToRemoteR :: (Remote arch, ArrayElt e, ArrayPtrs e ~ Ptr a, Storable a, Typeable a, Typeable e) => Int -> Int -> Maybe (StreamR arch) -> ArrayData e -> LLVM arch ()

-- | Copy a section of an array from the remote device back to the host.
--   The elements between the given indices (inclusive left, exclusive
--   right) are transferred.,v
copyToHostR :: (Remote arch, ArrayElt e, ArrayPtrs e ~ Ptr a, Storable a, Typeable a, Typeable e) => Int -> Int -> Maybe (StreamR arch) -> ArrayData e -> LLVM arch ()

-- | Copy a section of an array between two remote instances of the same
--   type. This may be more efficient than copying to the host and then to
--   the second remote instance (e.g. DMA between two CUDA devices). The
--   elements between the given indices (inclusive left, exclusive right)
--   are transferred.
copyToPeerR :: (Remote arch, ArrayElt e, ArrayPtrs e ~ Ptr a, Storable a, Typeable a, Typeable e) => Int -> Int -> arch -> Maybe (StreamR arch) -> ArrayData e -> LLVM arch ()

-- | Read a single element from the array at a given row-major index
indexRemote :: Remote arch => Array sh e -> Int -> LLVM arch e

-- | Create a new array from its representation on the host, and upload it
--   to a new remote array.
newRemote :: (Remote arch, Shape sh, Elt e) => sh -> (sh -> e) -> LLVM arch (Array sh e)

-- | Upload an immutable array from the host to the remote device. This is
--   a synchronous operation in that it will not return until the transfer
--   completes, but the individual array payloads will be uploaded
--   concurrently if possible.
useRemote :: (Remote arch, Arrays arrs) => arrs -> LLVM arch arrs

-- | Upload an immutable array from the host to the remote device,
--   asynchronously. This will upload each array payload in a separate
--   execution stream, thereby making us of multiple memcpy engines (where
--   available).
useRemoteAsync :: (Remote arch, Arrays arrs) => arrs -> StreamR arch -> LLVM arch (AsyncR arch arrs)

-- | Uploading existing arrays from the host to the remote device. This is
--   synchronous with respect to the calling thread, but the individual
--   array payloads may themselves be transferred concurrently.
copyToRemote :: (Remote arch, Arrays a) => a -> LLVM arch a

-- | Upload an existing array to the remote device, asynchronously.
copyToRemoteAsync :: (Remote arch, Arrays a) => a -> StreamR arch -> LLVM arch (AsyncR arch a)

-- | Copy an array from the remote device to the host. This is synchronous
--   with respect to the calling thread, but the individual array payloads
--   may themselves be transferred concurrently.
copyToHost :: (Remote arch, Arrays a) => a -> LLVM arch a

-- | Copy an array from the remote device to the host, asynchronously
copyToHostAsync :: (Remote arch, Arrays a) => a -> StreamR arch -> LLVM arch (AsyncR arch a)

-- | Copy arrays between two remote instances of the same type. This may be
--   more efficient than copying to the host and then to the second remote
--   instance (e.g. DMA between CUDA devices).
copyToPeer :: (Remote arch, Arrays a) => arch -> a -> LLVM arch a

-- | As <a>copyToPeer</a>, asynchronously.
copyToPeerAsync :: (Remote arch, Arrays a) => arch -> a -> StreamR arch -> LLVM arch (AsyncR arch a)

-- | Read a single element from an array at the given row-major index.
runIndexArray :: Monad m => (forall e a. (ArrayElt e, ArrayPtrs e ~ Ptr a, Storable a, Typeable a, Typeable e) => ArrayData e -> Int -> m a) -> Array sh e -> Int -> m e

-- | Generalised function to traverse the Arrays structure
runArrays :: (Functor m, Applicative m, Monad m, Arrays arrs) => arrs -> (forall sh e. Array sh e -> m (Array sh e)) -> m arrs

-- | Generalised function to traverse the ArrayData structure with one
--   additional argument
runArray :: (Functor m, Applicative m, Monad m) => Array sh e -> (forall e' p. (ArrayElt e', ArrayPtrs e' ~ Ptr p, Storable p, Typeable p, Typeable e') => ArrayData e' -> m (ArrayData e')) -> m (Array sh e)


module Data.Array.Accelerate.LLVM.Compile
class Compile arch where data family ExecutableR arch

-- | Compile an accelerate computation into some backend-specific
--   executable format
compileForTarget :: Compile arch => DelayedOpenAcc aenv a -> Gamma aenv -> LLVM arch (ExecutableR arch)

-- | Initialise code generation, compilation, and data transfer (if
--   required) for an array expression. The returned array computation is
--   annotated to be suitable for execution on the target:
--   
--   <ul>
--   <li>A list of the array variables embedded within scalar
--   expressions</li>
--   <li>The compiled LLVM code required to execute the kernel</li>
--   </ul>
compileAcc :: (Compile arch, Remote arch) => DelayedAcc a -> LLVM arch (ExecAcc arch a)
compileAfun :: (Compile arch, Remote arch) => DelayedAfun f -> LLVM arch (ExecAfun arch f)

-- | Annotate an open array expression with the information necessary to
--   execute each node directly.
data ExecOpenAcc arch aenv a
ExecAcc :: ExecutableR arch -> Gamma aenv -> PreOpenAcc (ExecOpenAcc arch) aenv a -> ExecOpenAcc arch aenv a
EmbedAcc :: PreExp (ExecOpenAcc arch) aenv sh -> ExecOpenAcc arch aenv (Array sh e)
type ExecAcc arch a = ExecOpenAcc arch () a
type ExecAfun arch a = PreAfun (ExecOpenAcc arch) a
type ExecExp arch = ExecOpenExp arch ()
type ExecOpenExp arch = PreOpenExp (ExecOpenAcc arch)
type ExecFun arch = ExecOpenFun arch ()
type ExecOpenFun arch = PreOpenFun (ExecOpenAcc arch)


module Data.Array.Accelerate.LLVM.Execute
class Remote arch => Execute arch
map :: (Execute arch, Shape sh, Elt b) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> sh -> LLVM arch (Array sh b)
generate :: (Execute arch, Shape sh, Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> sh -> LLVM arch (Array sh e)
transform :: (Execute arch, Shape sh, Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> sh -> LLVM arch (Array sh e)
backpermute :: (Execute arch, Shape sh, Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> sh -> LLVM arch (Array sh e)
fold :: (Execute arch, Shape sh, Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> sh :. Int -> LLVM arch (Array sh e)
fold1 :: (Execute arch, Shape sh, Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> sh :. Int -> LLVM arch (Array sh e)
foldSeg :: (Execute arch, Shape sh, Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> sh :. Int -> DIM1 -> LLVM arch (Array (sh :. Int) e)
fold1Seg :: (Execute arch, Shape sh, Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> sh :. Int -> DIM1 -> LLVM arch (Array (sh :. Int) e)
scanl :: (Execute arch, Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> DIM1 -> LLVM arch (Vector e)
scanl1 :: (Execute arch, Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> DIM1 -> LLVM arch (Vector e)
scanl' :: (Execute arch, Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> DIM1 -> LLVM arch (Vector e, Scalar e)
scanr :: (Execute arch, Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> DIM1 -> LLVM arch (Vector e)
scanr1 :: (Execute arch, Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> DIM1 -> LLVM arch (Vector e)
scanr' :: (Execute arch, Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> DIM1 -> LLVM arch (Vector e, Scalar e)
permute :: (Execute arch, Shape sh, Shape sh', Elt e) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> sh -> Array sh' e -> LLVM arch (Array sh' e)
stencil1 :: (Execute arch, Shape sh, Elt a, Elt b) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> Array sh a -> LLVM arch (Array sh b)
stencil2 :: (Execute arch, Shape sh, Elt a, Elt b, Elt c) => ExecutableR arch -> Gamma aenv -> AvalR arch aenv -> StreamR arch -> Array sh a -> Array sh b -> LLVM arch (Array sh c)
aforeign :: (Execute arch, Arrays as, Arrays bs, Foreign f) => f as bs -> ExecAfun arch (as -> bs) -> as -> LLVM arch bs

-- | A mapping between the environment index of a free array variable and
--   the Name of that array to be used in the generated code.
--   
--   This simply compresses the array indices into a continuous range,
--   rather than directly using the integer equivalent of the de Bruijn
--   index. Thus, the result is still sensitive to the order of let
--   bindings, but not of any intermediate (unused) free array variables.
type Gamma aenv = IntMap (Label, Idx' aenv)
executeAcc :: (Execute arch, Arrays a) => ExecAcc arch a -> LLVM arch a
executeAfun1 :: (Execute arch, Arrays a, Arrays b) => ExecAfun arch (a -> b) -> a -> LLVM arch b
