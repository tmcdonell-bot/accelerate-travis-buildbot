<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Foreign.CUDA.BLAS.Sparse</title><link href="ocean.css" rel="stylesheet" type="text/css" title="Ocean" /><script src="haddock-util.js" type="text/javascript"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script><script type="text/javascript">//<![CDATA[
window.onload = function () {pageLoad();};
//]]>
</script></head><body><div id="package-header"><ul class="links" id="page-menu"><li><a href="src/Foreign.CUDA.BLAS.Sparse.html">Source</a></li><li><a href="index.html">Contents</a></li><li><a href="doc-index.html">Index</a></li></ul><p class="caption">cusparse-0.1.0.0: FFI bindings to the CUDA Sparse BLAS library</p></div><div id="content"><div id="module-header"><table class="info"><tr><th valign="top">Copyright</th><td>[2017] Trevor L. McDonell</td></tr><tr><th>License</th><td>BSD3</td></tr><tr><th>Maintainer</th><td>Trevor L. McDonell &lt;tmcdonell@cse.unsw.edu.au&gt;</td></tr><tr><th>Stability</th><td>experimental</td></tr><tr><th>Portability</th><td>non-portable (GHC extensions)</td></tr><tr><th>Safe Haskell</th><td>None</td></tr><tr><th>Language</th><td>Haskell98</td></tr></table><p class="caption">Foreign.CUDA.BLAS.Sparse</p></div><div id="table-of-contents"><p class="caption">Contents</p><ul><li><a href="#g:1">Control</a></li><li><a href="#g:2">Operations</a></li></ul></div><div id="description"><p class="caption">Description</p><div class="doc"><p>The cuSPARSE library is an implementation of Sparse BLAS (Basic Linear
 Algebra Subprograms) for NVIDIA GPUs. Sparse matrices are those where the
 majority of elements are zero. Sparse BLAS routines are specifically
 implemented to take advantage of this sparsity.</p><p>To use operations from the cuSPARSE library, the user must allocate the
 required matrices and vectors in the GPU memory space, fill them with data,
 call the desired sequence of cuSPARSE functions, then copy the results from
 the GPU memory space back to the host.</p><p>The <a href="http://hackage.haskell.org/package/cuda">cuda</a> package can be used for
 writing to and retrieving data from the GPU.</p><dl><dt><em>Example</em></dt><dd></dd></dl><p>The following is based on the following example:</p><p><a href="http://docs.nvidia.com/cuda/cusparse/index.html#appendix-b-cusparse-library-c---example">http://docs.nvidia.com/cuda/cusparse/index.html#appendix-b-cusparse-library-c---example</a></p><p>It assumes basic familiarity with the <a href="http://hackage.haskell.org/package/cuda">cuda</a>
 package, as described in the <a href="../cuda-0.8.0.1/Foreign-CUDA-Driver.html">Foreign.CUDA.Driver</a> module.</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>import Foreign.CUDA.Driver      as CUDA
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>import Foreign.CUDA.BLAS.Sparse as Sparse
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>CUDA.initialise []
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>dev &lt;- CUDA.device 0
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>ctx &lt;- CUDA.create dev []
</code></strong></pre><p>We begin by creating the following matrix in COO format and transferring to
 the GPU:</p><p>\[
 \left(\begin{matrix}
   1.0 &amp;     &amp; 2.0 &amp; 3.0 \\
       &amp; 4.0 &amp;     &amp;     \\
   5.0 &amp;     &amp; 6.0 &amp; 7.0 \\
       &amp; 8.0 &amp;     &amp; 9.0
 \end{matrix}\right)
 \]</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>let n = 4
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>let nnz = 9
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>d_cooRowIdx &lt;- newListArray [ 0,0,0, 1, 2,2,2, 3,3 ]  :: IO (DevicePtr Int32)
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>d_cooColIdx &lt;- newListArray [ 0,2,3, 1, 0,2,3, 1,3 ]  :: IO (DevicePtr Int32)
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>d_vals      &lt;- newListArray [ 1..9 ]                  :: IO (DevicePtr Double)
</code></strong></pre><p>Create a sparse and dense vector:</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>let nnz_vector = 3
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>d_xVal &lt;- newListArray [ 100, 200, 400 ] :: IO (DevicePtr Double)
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>d_xIdx &lt;- newListArray [ 0,   1,   3 ]   :: IO (DevicePtr Int32)
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>d_y    &lt;- newListArray [ 10, 20 .. 80 ]  :: IO (DevicePtr Double)
</code></strong></pre><p>Initialise the cuSPARSE library and set up the matrix descriptor:</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>hdl &lt;- Sparse.create
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>mat &lt;- Sparse.createMatDescr
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>Sparse.setMatrixType mat General
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>Sparse.setIndexBase mat Zero
</code></strong></pre><p>Exercise the conversion routines to convert from COO to CSR format:</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>d_csrRowPtr &lt;- CUDA.mallocArray (n+1) :: IO (DevicePtr Int32)
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>xcoo2csr hdl d_cooRowIdx nnz n d_csrRowPtr Zero
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>peekListArray (n+1) d_csrRowPtr
</code></strong>[0,3,4,7,9]
</pre><p>Scatter elements from the sparse vector into the dense vector:</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>dsctr hdl nnz_vector d_xVal d_xIdx (d_y `plusDevPtr` (n * sizeOf (undefined::Double))) Zero
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>peekListArray 8 d_y
</code></strong>[10.0,20.0,30.0,40.0,100.0,200.0,70.0,400.0]
</pre><p>Multiply the matrix in CSR format with the dense vector:</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>with 2.0 $ \alpha -&gt;
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>with 3.0 $ \beta  -&gt;
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>dcsrmv hdl N n n nnz alpha mat d_vals d_csrRowPtr d_cooColIdx d_y beta (d_y `plusDevPtr` (n * sizeOf (undefined::Double)))
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>peekListArray 8 d_y
</code></strong>[10.0,20.0,30.0,40.0,680.0,760.0,1230.0,2240.0]
</pre><p>Multiply the matrix in CSR format with a dense matrix:</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>d_z &lt;- CUDA.mallocArray (2*(n+1)) :: IO (DevicePtr Double)
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>memset (castDevPtr d_z :: DevicePtr Word8) (2*(n+1)*sizeOf (undefined::Double)) 0
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>with 5.0 $ \alpha -&gt;
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>with 0.0 $ \beta  -&gt;
</code></strong><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>dcsrmm hdl N n 2 n nnz alpha mat d_vals d_csrRowPtr d_cooColIdx d_y n beta d_z (n+1)
</code></strong>&gt;&gt; peekListArray (2*(n+1)) d_z
[950.0,400.0,2550.0,2600.0,0.0,49300.0,15200.0,132300.0,131200.0,0.0]
</pre><p>Finally, we should <code><a href="../cuda-0.8.0.1/Foreign-CUDA-Driver.html#v:free">free</a></code> the device memory we allocated,
 and release the Sparse BLAS context handle:</p><pre class="screen"><code class="prompt">&gt;&gt;&gt; </code><strong class="userinput"><code>Sparse.destroy hdl
</code></strong></pre><dl><dt><em>Additional information</em></dt><dd></dd></dl><p>For more information, see the NVIDIA cuSPARSE documentation:</p><p><a href="http://docs.nvidia.com/cuda/cusparse/index.html">http://docs.nvidia.com/cuda/cusparse/index.html</a></p></div></div><div id="synopsis"><p id="control.syn" class="caption expander" onclick="toggleSection('syn')">Synopsis</p><ul id="section.syn" class="hide" onclick="toggleSection('syn')"><li class="src short">module <a href="Foreign-CUDA-BLAS-Sparse-Context.html">Foreign.CUDA.BLAS.Sparse.Context</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Sparse-Analysis.html">Foreign.CUDA.BLAS.Sparse.Analysis</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Sparse-Error.html">Foreign.CUDA.BLAS.Sparse.Error</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Sparse-Matrix-Descriptor.html">Foreign.CUDA.BLAS.Sparse.Matrix.Descriptor</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Sparse-Matrix-Hybrid.html">Foreign.CUDA.BLAS.Sparse.Matrix.Hybrid</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Sparse-Stream.html">Foreign.CUDA.BLAS.Sparse.Stream</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Sparse-Level1.html">Foreign.CUDA.BLAS.Sparse.Level1</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Sparse-Level2.html">Foreign.CUDA.BLAS.Sparse.Level2</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Sparse-Level3.html">Foreign.CUDA.BLAS.Sparse.Level3</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Sparse-Precondition.html">Foreign.CUDA.BLAS.Sparse.Precondition</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Sparse-Reorder.html">Foreign.CUDA.BLAS.Sparse.Reorder</a></li><li class="src short">module <a href="Foreign-CUDA-BLAS-Sparse-Convert.html">Foreign.CUDA.BLAS.Sparse.Convert</a></li></ul></div><div id="interface"><h1 id="g:1">Control</h1><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Sparse-Context.html">Foreign.CUDA.BLAS.Sparse.Context</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Sparse-Analysis.html">Foreign.CUDA.BLAS.Sparse.Analysis</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Sparse-Error.html">Foreign.CUDA.BLAS.Sparse.Error</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Sparse-Matrix-Descriptor.html">Foreign.CUDA.BLAS.Sparse.Matrix.Descriptor</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Sparse-Matrix-Hybrid.html">Foreign.CUDA.BLAS.Sparse.Matrix.Hybrid</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Sparse-Stream.html">Foreign.CUDA.BLAS.Sparse.Stream</a></p></div><h1 id="g:2">Operations</h1><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Sparse-Level1.html">Foreign.CUDA.BLAS.Sparse.Level1</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Sparse-Level2.html">Foreign.CUDA.BLAS.Sparse.Level2</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Sparse-Level3.html">Foreign.CUDA.BLAS.Sparse.Level3</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Sparse-Precondition.html">Foreign.CUDA.BLAS.Sparse.Precondition</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Sparse-Reorder.html">Foreign.CUDA.BLAS.Sparse.Reorder</a></p></div><div class="top"><p class="src">module <a href="Foreign-CUDA-BLAS-Sparse-Convert.html">Foreign.CUDA.BLAS.Sparse.Convert</a></p></div></div></div><div id="footer"><p>Produced by <a href="http://www.haskell.org/haddock/">Haddock</a> version 2.18.1</p></div></body></html>